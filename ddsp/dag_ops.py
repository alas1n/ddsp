# Copyright 2020 The DDSP Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Lint as: python3
"""Library of functions and layers of Directed Acyclical Graphs.

DAGLayer exists as an alternative to manually specifying the forward pass in
python. The advantage is that a variety of configurations can be
programmatically specified via external dependency injection, such as with the
`gin` library.
"""

from typing import Dict, Sequence, Tuple, Text, TypeVar

from ddsp import core
import gin
import tensorflow.compat.v2 as tf

tfkl = tf.keras.layers

# Define Types.
TensorDict = Dict[Text, tf.Tensor]
KeyOrModule = TypeVar('KeyOrModule', Text, tf.Module)
Node = Tuple[KeyOrModule, Sequence[Text], Sequence[Text]]
DAG = Sequence[Node]

# Helper Functions for DAGs  ---------------------------------------------------
filter_by_value = lambda d, cond: dict(filter(lambda e: cond(e[1]), d.items()))
is_module = lambda v: isinstance(v, tf.Module)
# Duck typing.
is_loss = lambda v: hasattr(v, 'get_losses_dict')
is_processor = lambda v: hasattr(v, 'get_signal') and hasattr(v, 'get_controls')


# pylint: disable=unused-argument
@gin.configurable(whitelist=['verbose'])  # For debugging.
def run_dag(modules_obj: object,
            dag: DAG,
            inputs: TensorDict,
            verbose: bool = True,
            **kwargs) -> TensorDict:
  """Connects and runs submodules of dag.

  Args:
    modules_obj: Object containing submodules as attributes to wire together
      with a dag.
    dag: A directed acyclical graph in the form of a list of nodes. Each node
      has the form

      ['module_key', ['input_key', ...], ['optional_output_key', ...]]

      'module_key': String for attribute name of module. For example,
        'encoder' woud access the attribute `dag_layer.encoder`.
      'input_key': List of strings, nested keys in dictionary of dag outputs.
        For example, 'inputs/f0_hz' would access `outputs[inputs]['f0_hz']`.
        Inputs to the dag are wrapped in a `inputs` dict as shown in the
        example. This list is ordered and has one key per a module input
        argument. Each node's outputs are prefixed by their module name.
      'optional_output_key': Optional list of strings, keys for each return
        value for the module. For example, ['amps', 'freqs'] would have the
        module return a dictionary {'module_name': {'amps': return_value_0,
        'freqs': return_value_1}}. If the module returns a dictionary, the
        keys of the dictionary will be used and these values (if provided)
        will be ignored. If not, and no output keys are provided, enumerated
        numbers will be used as keys (e.g. {'module_name':
        {'0': return_value_0, '1': return_value_1}})

      The graph is read sequentially and must be topologically sorted. This
      means that all inputs for a module must already be generated by earlier
      modules (or in the input dictionary).
    inputs: A dictionary of input tensors fed to the dag. If a list is provided
      it will be converted into enumerated dictionary keys
      {'inputs':{'0': inputs[0], '1': inputs[1], ...}} etc.
    verbose: Print out dag routing when running.
    **kwargs: Other kwargs to pass to submodules, such as keras kwargs.

  Returns:
    A nested dictionary of all the output tensors. If the dag has an
      output node as specified by 'out', 'output', or 'outputs', only returns
      the tensor(s) that are inputs to that ndoe.
  """
  inputs = core.copy_if_tf_function(inputs)
  # Initialize the outputs with inputs to the dag.
  outputs = {'inputs': inputs}
  # TODO(jesseengel): Remove this cluttering of the base namespace. Only there
  # for backwards compatability.
  outputs.update(inputs)

  # Run through the DAG nodes in sequential order.
  for node in dag:
    # Get the node processor and keys to the node input.
    module_key, input_keys = node[0], node[1]
    # Get the module.
    module = getattr(modules_obj, module_key)
    # Optionally specify output keys if module does not return dict.
    output_keys = node[2] if len(node) > 2 else None

    # Get the inputs to the node.
    try:
      inputs = [core.nested_lookup(key, outputs) for key in input_keys]
    except KeyError as e:
      raise KeyError(f'{e} InputKeys:{tuple(input_keys)}, '
                     f'AvailableKeys:{core.nested_keys(outputs)}') from e

    if verbose:
      shape = lambda d: tf.nest.map_structure(lambda x: list(x.shape), d)
      print(f'Input to Module: {module_key}\nKeys: {input_keys}\n'
            f'In: {shape(inputs)}\n')

    if is_processor(module):
      # Processor modules.
      module_outputs = module(*inputs, return_outputs_dict=True, **kwargs)
    else:
      # Network modules.
      module_outputs = module(*inputs, **kwargs)
      module_outputs = core.to_dict(module_outputs, output_keys)

    if verbose:
      print(f'Output from Module: {module_key}\n'
            f'Out: {shape(module_outputs)}\n')

    # Add module outputs to the dictionary.
    outputs[module_key] = module_outputs

  # Alias final module output as dag output.
  # 'out' is a reserved key for final dag output.
  outputs['out'] = module_outputs

  return outputs
# pylint: enable=unused-argument


def split_keras_kwargs(kwargs):
  """Strip keras specific kwargs."""
  keras_kwargs = {}
  for key in ['training', 'mask', 'name']:
    if kwargs.get(key) is not None:
      keras_kwargs[key] = kwargs.pop(key)
  return keras_kwargs, kwargs


def extract_modules_from_dag(dag, condition):
  """Remove modules from dag, and replace with module names."""
  modules = {}
  if dag is None:
    return dag, modules
  else:
    dag = list(dag)  # Make mutable in case it's a tuple.
    for i, node in enumerate(dag):
      node = list(node)  # Make mutable in case it's a tuple.
      module = node[0]
      if condition(module):
        # Strip module from the dag.
        modules[module.name] = module
        # Replace with module name.
        node[0] = module.name
      dag[i] = node
    return dag, modules


# DAG and ProcessorGroup Classes -----------------------------------------------
@gin.register
class DAGLayer(tfkl.Layer):
  """String modules together."""

  def __init__(self, dag: DAG, **kwargs):
    """Constructor.

    Args:
      dag: A directed acyclical graph in the form of a list of nodes. Each node
        has the form

        ['module_key', ['input_key', ...], ['optional_output_key', ...]]

        'module_key': String for attribute name of module. For example,
          'encoder' woud access the attribute `dag_layer.encoder`.
        'input_key': List of strings, nested keys in dictionary of dag outputs.
          For example, 'inputs/f0_hz' would access `outputs[inputs]['f0_hz']`.
          Inputs to the dag are wrapped in a `inputs` dict as shown in the
          example. This list is ordered and has one key per a module input
          argument. Each node's outputs are prefixed by their module name.
        'optional_output_key': Optional list of strings, keys for each return
          value for the module. For example, ['amps', 'freqs'] would have the
          module return a dictionary {'module_name': {'amps': return_value_0,
          'freqs': return_value_1}}. If the module returns a dictionary, the
          keys of the dictionary will be used and these values (if provided)
          will be ignored. If not, and no output keys are provided, enumerated
          numbers will be used as keys (e.g. {'module_name':
          {'0': return_value_0, '1': return_value_1}})

        The graph is read sequentially and must be topologically sorted. This
        means that all inputs for a module must already be generated by earlier
        modules (or in the input dictionary).
      **kwargs: Other keras kwargs such as 'name'.
    """
    keras_kwargs, kwargs = split_keras_kwargs(kwargs)
    super().__init__(**keras_kwargs)

    # Create properties/submodules from other kwargs.
    modules = filter_by_value(kwargs, is_module)
    self.__dict__.update(modules)
    self.modules = list(modules.values())

    dag, modules = extract_modules_from_dag(dag, is_module)
    self.__dict__.update(modules)
    self.modules += list(modules.values())
    self.dag = dag
    print('Created DAG:\n', self.dag)

  def call(self, inputs: TensorDict) -> tf.Tensor:
    """Like Processor, but specific to having an input dictionary."""
    return run_dag(self, self.dag, inputs)


